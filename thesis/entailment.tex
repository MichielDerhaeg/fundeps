\chapter{Constraint Entailment}
\label{cha:entailment}
%TODO rule names in spec
In this chapter we describe a concrete constraint solver based on the
$OutsideIn(X)$~\cite{outsideinx-modular-type-inference-with-local-assumptions}
inference framework. It is based on the particular constraint solver for the
constraint domain $X$ instantiated with
\[
X = \textit{type classes} + \textit{GADTs} + \textit{type families}
\]
presented in the same work. This solver will be referred to simply as
$OutsideIn(X)$ from now on. Because our work does not consider $GADTs$ or other
features that might generate local constraints, the part of the solver that
deals with those constraints is not implemented.

$OutsideIn(X)$ was designed with generating evidence in mind but any concrete
specification as to how has been omitted. This chapter contains a description of
the implementation including how evidence is generated during constraint
solving.

\section{Motivation}
\textit{"Solving equality contraints is
tricky."}~\cite{outsideinx-modular-type-inference-with-local-assumptions}
Consider the following example:
\begin{verbatim}
    class C a b | a -> b
    instance C Int Bool
\end{verbatim}
$\quad\quad\quad\rightsquigarrow$ $F$ $Int$ $\sim$ $Bool$
\begin{verbatim}
    f :: C Int b => b -> Bool
    f x = x
\end{verbatim}

In the end the $b \sim Bool$ wanted constraint somehow has to be solved. This
can be achieved by using the information provided by the class constraint in the
type signature. It gives rise to the given equality constraint $F \; Int \sim
b$. This information can be used to replace $b$ in the wanted constraint
resulting in $F \; Int \sim Bool$. Which is the same as the equality axiom
generated by the instance declaration and it therefore can be easily resolved.
Note that we replace $b$ with $F \; Int$. The wanted constraint that contains no
type families is replaced with one that does. To see why this
could be potentially dangerous, consider the following type signature.
\begin{verbatim}
    g :: C a a => a -> a
\end{verbatim}
This would give rise to the given constraint $F \; a \sim a$. This could be used
to replace any occurrence of $a$ with $F \; a$, but because the latter contains
$a$ itself this can be repeated indefinitely. Being able to replace simple
constraints by constraints containing type families is essential, but is a serious threat to the
termination of the solving algorithm.
%TODO find example that replaces a tv with fam once, but doing so multiple times
%would be harmful

The issues described in the last example have been addressed by Schrijvers et
al.~\cite{type-checking-with-open-type-functions} in their work about open type
functions. This solution takes local given constraints produced by GADTs into
account which is a similar problem. The $OutsideIn(X)$ constraint solver
implements a reworked version that is simpler and has worked out
interoperability with type classes.

\section{Overview}

\begin{figure}
\[ % george doesn't like '$$'
P ; \overline{untchs} \vDash \mathcal{C} \rightsquigarrow
(\mathcal{P}_{residual}, \theta, \eta)_\bot
\]
\caption{Constraint Entailment}
\end{figure}

The constraint solver takes the program theory $P$ containing the top-level
information and \textit{given} constraints, a set of untouchable (rigid) type variables
$\overline{untchs}$, (that is, variables the constraint solver is not allowed
to unify), and a set of \textit{wanted} constraints $\mathcal{C}$ the constraint solver is expected to resolve.

Notice that the original version of $OutsideIn(X)$ uses \textit{touchable} variables instead, a set of
type variables the constraint solver \textit{is} allowed to unify. We have opted to do
the opposite; this is simply a matter of taste and has no interesting
consequences.

Entailment provides us with residual annotated class constraints that could not
be solved. Residual equality constraints are not allowed: when some cannot be
resolved our solver simply fails. These residual constraints can be quantified over
in the inferred type. Because equality constraints are not allowed in the
source language we disallow residual equality constraints for simplicity.

There are several reasons why entailment could fail which is why the result is
annotated with $\bot$. This usually indicates a fatal failure, meaning the
compiler has to give up and present an error to the user.

Most importantly, the result of the entailment relation comes in the form of a
type substitution and an evidence solution to be applied to the elaborated
System $F_C$ term to replace the placeholder variables with the inferred types,
coercions, and dictionary terms.

The strategy the solver employs involves computing the fixed point of a set of
rewrite rules applied to the set of given and wanted constraints. In other
words, we repeatedly apply several rewrite rules until no rule applies and the
constraints have reached a normal form where the constraints closely resemble a
type substitution.

Most of these rules have a wanted and given variant. Both often share many
similarities but mainly differ in how they handle evidence. Wanted constraints
are annotated with evidence variables that eventually need to be substituted
with evidence for why these original constraints hold. Every time a rule
rewrites a constraint, a part of the substitution is constructed that mimics the
change in the constraint. One could say the evidence is a trace of all steps the
solver took to prove the constraint. E.g. $c : Maybe \; a \sim Maybe \; b$ could
be simplified to $c': a \sim b$, which would generate $[c \mapsto \langle Maybe
\rangle \; c']$ as evidence for the transition. %TODO c'

With given constraints, essentially the reverse is true. These constraints are
already annotated with the evidence for why they hold. When a constraint is
changed, the evidence will be adapted to hold for the new constraints. E.g.
$\gamma : Maybe \; a \sim Maybe \; b$ will be changed to $(\text{right}\; \gamma) :
a \sim b$.

\section{Rewrite Rules}
In this section we describe and specify the various constraint rewrite rules
used by the constraint solver. If one such rule matches a constraint, this
constraint will be removed from the constraint set and replaced by the output
constraints of the rule. Other than constraints, these rules might produce
additional by-products as a side-effect of matching a constraint. For example,
matching wanted constraints usually produces an evidence substitution.

%TODO mention implicit state (monad)?

\subsection{Canonicalization}
\label{sec:canonicalization}

Canonicalization, specified in figures~\ref{fig:canon_w} and \ref{fig:canon_g},
transforms a single constraint to a simpler form. Constraints that cannot be
simplified further by canonicalization have a very particular shape and are
called \textit{canonical constraints}. These are specified in
figure~\ref{fig:canon-cs}.

\begin{figure}
\fbox{$\vdash_{can} Q$}
\begin{mathpar}
\inferrule*[right=CEQ]
{
    a \prec u
    \\
    a \notin fv(u)
}
{
    \vdash_{can} a \sim u
}
\quad
\inferrule*[right=CFEQ]
{
    ~
}
{
    \vdash_{can} F(\overline{u}) \sim u
}
\quad
\inferrule*[right=CDICT]
{
    ~
}
{
    \vdash_{can} TC \; \overline{u}
}
\end{mathpar}
\caption{Canonical Constraints}
\label{fig:canon-cs}
\end{figure}

\subsubsection{Decomposing types}
%TODO nothing really new or exciting here, highly similar to parts of
%unification

% GEORGE: DON'T FORGET TO WRITE THIS.

\subsubsection{Occurrence check}
Constraints like $a \sim [a]$ would, if left to their devices, result in
infinite types and result in loss of termination. These issues are detected
during canonicalization and would cause a fatal error and return $\bot$. Note that
this rule $(a \sim u)$ where $a \in fv(u) \;$ matches only if the other type
does not contain any type families.
\begin{verbatim}
    class Coll c e | c -> e
    f :: Coll [a] a => ..
\end{verbatim}
The type signature is this example gives rise to the $F \; [a] \sim a$ given
constraint. This is perfectly fine, these situations do not necessarily cause
termination issues under type families.

\subsubsection{Orientation}
Canonicalization uses the $\prec$ relation of figure~\ref{fig:orientation} to put the
constraints in a specific orientation. Type families are put on the left of the
constraint equality. With no families, type variables are put on the left. This
is done so we can concisely control in the other rules what happens to constraints with and without type
families. In the case of constraints with two type
variables a total ordering is used to ensure termination. The exact ordering is not of importance;
its existence is what matters.
When one variable is untouchable and the other is not, the
touchable is preffered on the left simply to make the constraint look more like
a substitution. When they are both untouchable or
touchable, lexicographical order is used.
%TODO actually, unique's are used for order on names, it's faster and cleaner.

One needs to be careful when implementing the ordering so that it does not hold
in both directions, thus risking non-termination.

\begin{figure}
%TODO explain real a \prec b or put it in figure?
%TODO put in untchs param
\fbox{$\tau_1 \prec \tau_2$}
\[
\begin{array}{l c l l}
F(\overline{\tau}) &\prec& \tau &\text{when} \; \tau \not\equiv
F'(\overline{\tau}')
\\
a &\prec& b &\text{when} \; a \notin \overline{untchs}
\\
a &\prec& b &\text{when} \; a < b \; \text{lexicographically}
\\
a &\prec& u
\end{array}
\]
\caption{Orientation}
\label{fig:orientation}
\end{figure}

\subsubsection{Flattening}
Type families are not allowed to appear nested as part of other types in
canonical constraints. The flattening procedure extracts those type families and
splits up the constraint. For example: %TODO cite example source
$$
a \sim [F \; a]
$$
becomes
$$
a \sim [\beta], F \; a \sim \beta
$$
where $\beta$ is a fresh type variable and additionally a substitution $[\beta
\mapsto F \; a]$ is produced. We replace the type family with the fresh variable
$\beta$ and create evidence so we can reconstruct the original type when we are
done solving constraints. In conjunction with the orientation, this is also done
to easily control interaction with type families even when they appear nested as
part of other types so they can be handled by different rules and that certain
transformations only occur once.

%TODO explain flattening substitution

%TODO specify extraction procedure? rename in code to matchXContext or something
The syntax related to this extraction is specified in
figure~\ref{fig:flattening-contexts}. The flattening contexts are simply type
patterns, type family applications or class constraints with a hole (denoted by
$\mathbb{T}$, $\mathbb{F}$, and $\mathbb{C}$ respectively). In practice, matching
on these contexts involves doing depth-first search on the monotype to find the
deepest nested type family and replacing them with the hole. Matching on
$\mathbb{F}[F \; \overline{u}]$ means performing this search, matching the rule
if it succeeds and returning $\mathbb{F}$ and $F \; \overline{u}$ as an output.
These contexts are implemented simply using functions, which is the easiest way to
enforce that non-linear, tree-like structures have only one hole.

%TODO specify and describe coTy substitution somewhere probably generic part
%about evidence

\begin{figure}
\[
\begin{array}{l c l}
\mathbb{T} &::=& T \mid \mathbb{T} \; \mathbb{T} \mid a \mid \bullet\\
\mathbb{F} &::=& F \; \overline{\mathbb{T}}\\
\mathbb{C} &::=& TC \; \overline{\mathbb{T}}
\end{array}
\]
\caption{Flattening Contexts}
\label{fig:flattening-contexts}
\end{figure}

\begin{figure}
\small
\fbox{$canon_w(\mathcal{Q}) = {\mathcal{Q}' \mid \eta}_\bot$}
\[
\begin{array}{l c l}
canon_w(c : \tau \sim \tau) &=& \bullet \mid c \mapsto \langle \tau \rangle
\\
canon_w(c : \tau_1 \; \tau_2 \sim \tau_3 \; \tau_4) &=& \{c_1 : \tau_1 \sim
\tau_3, c_2 : \tau_2  \sim \tau_4\} \mid c \mapsto c_1 \; c_2
\\ \where c_1, c_2 \; \text{fresh}
\\
canon_w(c : T_1 \sim T_2)
\\ \guard T_1 \neq T_2 &=& \bot
\\
canon_w(c : a \sim u)
\\ \guard a \in fv(u) \; \&\& \; u \neq a &=& \bot
\\
canon_w(c : \tau_1 \sim \tau_2)
\\ \qquad \mid \tau_2 < \tau_1 &=& c' : \tau_2 \sim \tau_1 \mid c \mapsto \text{sym}
\; c'
\\ \where c' \; \text{fresh}
\\
canon_w(d : \mathbb{D}[F(\overline{u})]) &=& \{ c_1 : F(\overline{u}) \sim \beta,
d_2 : \mathbb{D}[\beta]\} \mid d \mapsto d_2 \triangleright \gamma
\\ \multicolumn{3}{l}{\where \beta, c_1, d_2 \; \text{fresh}, [\beta \mapsto
F(\overline{u})](\text{sym} \; c_1, \mathbb{D}[\beta]) \rightsquigarrow (\gamma,
\pi)}
\\
canon_w(c : \mathbb{F}[F(\overline{u})] \sim \tau) &=& \{c_1 : F(\overline{u})
\sim \beta, c_2 : \mathbb[\beta] \sim \tau \} \mid c \mapsto (\text{sym} \; \gamma)
\fctrans c_2
\\ \multicolumn{3}{l}{\where \beta, c_1, d_2 \; \text{fresh},
[\beta \mapsto F(\overline{u})](\text{sym} \;
c_1, \mathbb{F}[\beta]) \rightsquigarrow (\gamma, \tau)}
\\
canon_w(c : \tau \sim \mathbb{T}[F(\overline{u})])
\\ \qquad \mid \tau \equiv F'(\overline{u}') \; || \; \tau \equiv \alpha &=&
\{c_1 : F(\overline{u}) \sim \beta, c_2 : \tau \sim \mathbb{T}[\beta]\} \mid c
\mapsto c_2 \fctrans \gamma
\\ \multicolumn{3}{l}{\where \beta, c_1, d_2 \; \text{fresh},
[\beta \mapsto F(\overline{u})](\text{sym} \;
c_1, \mathbb{T}[\beta]) \rightsquigarrow (\gamma, \tau')}
\end{array}
\]
\caption{Canonicalize Wanted Constraints}
\label{fig:canon_w}
\end{figure}

\begin{figure}
\small
\fbox{$canon_g(\mathcal{Q}_g) = {\mathcal{Q}_g' \mid \overline{untch} ; \theta ;
\eta}_\bot$}
\[
\begin{array}{l c l}
canon_g(\gamma : \tau \sim \tau) &=& \bullet \mid \bullet ; \bullet ; \bullet
\\
canon_g(\gamma : \tau_1 \; \tau_2 \sim \tau_3 \; \tau_4) &=& \{ \text{left} \;
\gamma : \tau_1 \sim \tau_3, \text{right} \; \gamma : \tau_2 \sim \tau_4\} \mid
\bullet ; \bullet ; \bullet
\\
canon_g(\gamma : T_1 \sim T_2)
\\ \qquad \mid T_1 \neq T_2 &=& \bot
\\
canon_g(\gamma : a \sim u)
\\
\qquad \mid a \in fv(u) \; \&\& \; u \neq a &=& \bot
\\
canon_g(\gamma : \tau_1 \sim \tau_2)
\\ \guard \tau_2 < \tau_1 &=& \text{sym} \; \gamma : \tau_2 \sim \tau_1
\mid \bullet ; \bullet ; \bullet
\\
canon_g(t : \mathbb{D}[F(\overline{u})]) &=& \{ d : \mathbb{D}[\beta], c :
F(\overline{u}) \sim \beta\}
\\ \where \beta, c, d \; \text{fresh} && \mid \{\beta\} ; \beta \mapsto F(\overline{u}) ; [c
\mapsto \langle F(\overline{u}) \rangle, d \mapsto t]
\\
canon_g(\gamma : \mathbb{F}[F(\overline{u})] \sim \tau) &=& \{ c_1 :
\mathbb{F}[\beta] \sim \tau, c_2 : F(\overline{u}) \sim \beta\}
\\ \where \beta, c_1, c_2 \; \text{fresh} && \mid \{ \beta \} ; \beta \mapsto F(\overline{u}) ; \; [c_1 \mapsto \gamma,
c_2 \mapsto \langle F(\overline{u}  \rangle)]
\\
canon_g(c : \tau \sim \mathbb{T}[F(\overline{u})])
\\ \guard \tau \equiv F'(\overline{u}') \; || \; \tau \equiv \alpha &=&
\{ c_1 : \tau \sim \mathbb{T}[\beta], c_2 : F(\overline{u}) \sim \beta\}
\\ \where \beta, c_1, c_2 \; \text{fresh} && \mid \{\beta\} ; \beta \mapsto F(\overline{u}) ; [c_1 \mapsto \gamma, c_2
\mapsto \langle F(\overline{u}) \rangle]
\end{array}
\]
\caption{Canonicalize Given Constraints}
\label{fig:canon_g}
\end{figure}

\subsection{Binary interaction}
\label{sec:binary-interaction}
The binary interaction rules are specified in figures~\ref{fig:interact_w} and
\ref{fig:interact_g} and transform two given or wanted \textit{canonical
constraints} to either given or wanted constraints respectively.

For equality constraints, this rule expresses a similar notion as type
substitution. The first constraint is used as a left-to-right substitution and
all occurrences of the left-hand, usually a type variable, are replaced by the
right-hand side in the second constraint. Note that because we only use
canonical constraints, type family applications will only be replaced with type
patterns and we never introduce additional type families. The total number can
only decrease and this is essential for termination.
%TODO mention total order termination stuff?

Binary interactions also remove duplicates of type class constraints. This
makes a lot of sense for wanted constraints: if we solved one, we can also solve
the other and the evidence of $[d_2 \rightarrow d_1$] clearly reflects this
notion. For given constraints however, we do the same but simply throw away the
evidence for one of them. This has no consequences because the coherence property of type
classes is enforced. This means that there should only be one unique choice for
an instance for any given type. The property implies that if the evidence can be
derived in multiple ways, it should semantically be the same. So there is no
loss of information.
%TODO example?
%TODO cite coherence

Every rule returns the first constraint it consumes unmodified. This
could be implemented by only consuming the second constraint instead, if desired.

\begin{figure}
\small
\fbox{$interact_w(\mathcal{Q}_1, \mathcal{Q}_2) = \mathcal{Q}' \mid \eta$}
\[
\begin{array}{l c l}
interact_w(c_1 : a \sim u_1, c_2 : a \sim u_2) &=& \{c_1 : a \sim u_1, c_2' :
u_1 \sim u_2\} \mid c_2 \mapsto c_1 \fctrans c_2'
\\ \where c_2' \; \text{fresh}
\\
interact_w(c_1 : a \sim u_1, c_2 : b \sim u_2)
\\ \guard a \in fv(u_2 )&=& \{c_1 : a  \sim u_1, c_2' : b \sim \tau\} \mid
c_2 \mapsto c_2' \fctrans \text{sym} \; \gamma
\\ \where [a \mapsto u_1](c_1, u_2) \rightsquigarrow (\gamma, \tau),
\\ \whereindent c_2' \; \text{fresh}
\\
interact_w(c_1 : a \sim u_1, c_2 : F(\overline{u}) \sim u_2)
\\ \guard a \in fv(\overline{u}, u_2) &=& \{c_1 : a \sim u_1, c_2' : \tau_1
\sim \tau_2\} \mid c_2 \mapsto \gamma_1 \fctrans c_2' \fctrans \text{sym} \;
\gamma_2
\\ \where [a \mapsto u_1](c_1, F(\overline{u})) \rightsquigarrow
(\gamma_1, \tau_1),
\\ \whereindent [a \mapsto u_1](c_1, u_2) \rightsquigarrow
(\gamma_2, \tau_2),
\\ \whereindent c_2' \; \text{fresh}
\\
interact_w(c : a \sim u, d : TC \; \overline{u})
\\ \guard a \in fv(\overline{u}) &=& \{c : a \sim u, d' : \pi\} \mid d
\mapsto d' \triangleright \text{sym} \; \gamma
\\ \where [a \mapsto u](c, TC \; \overline{u}) \rightsquigarrow
(\gamma, \pi)
\\ \whereindent d' \; \text{fresh}
\\
interact_w(c_1 : F(\overline{u}) \sim u_1, c_2 : F(\overline{u}) \sim u_2) &=&
\{c_1 : F(\overline{u}) \sim u_1, c_2' : u_1 \sim u_2\} \mid c_2 \mapsto c_1
\fctrans c_2'
\\
interact_w(d_1 : TC \; \overline{u}, d_2 : TC \; \overline{u}) &=& d_1 : TC \;
\overline{u} \mid d_2 \mapsto d_1
\end{array}
\]
\caption{Wanted Binary Interaction Rules}
\label{fig:interact_w}
\end{figure}

\begin{figure}
\small
\fbox{$interact_g(\mathcal{Q}_1, \mathcal{Q}_2) = \mathcal{Q}'$}
\[
\begin{array}{l c l}
interact_g(\gamma_1 : a \sim u_1, \gamma_2 : a \sim u_2) &=& \{\gamma_1 : a \sim
u_1, \text{sym} \; \gamma_1 \fctrans \gamma_2 : u_1 \sim u_2\}
\\
interact_g(\gamma_1 : a \sim u_1, \gamma_2 : b \sim u_2)
\\ \guard a \in fv(u_2 )&=& \{\gamma_1 : a  \sim u_1, \gamma_2 \fctrans \gamma :
b \sim \tau\}
\\ \where [a \mapsto u_1](\gamma_1, u_2) \rightsquigarrow (\gamma, \tau)
\\
interact_g(\gamma_1 : a \sim u_1, \gamma_2 : F(\overline{u}) \sim u_2)
\\ \guard a \in fv(\overline{u}, u_2) &=& \{\gamma_1 : a \sim u_1, \text{sym} \;
\gamma_1' \fctrans \gamma_2 \fctrans \gamma_2': \tau_1 \sim \tau_2\}
\\ \where [a \mapsto u_1](\gamma_1, F(\overline{u})) \rightsquigarrow
(\gamma_1', \tau_1)
\\ \whereindent [a \mapsto u_1](\gamma_1, u_2) \rightsquigarrow
(\gamma_2', \tau_2)
\\
interact_g(\gamma : a \sim u, t : TC \; \overline{u})
\\ \qquad \mid a \in fv(\overline{u}) &=& \{\gamma : a \sim u, t \triangleright
\gamma' : \pi\}
\\ \where [a \mapsto u](\gamma, TC \; \overline{u}) \rightsquigarrow
(\gamma', \pi)
\\
%TODO guard for equality?
interact_g(\gamma_1 : F(\overline{u}) \sim u_1, \gamma_2 : F(\overline{u}) \sim
u_2) &=& \{\gamma_1 : F(\overline{u}) \sim u_1, \text{sym} \; \gamma_1 \fctrans
\gamma_2: u_1 \sim u_2\}
\\
interact_g(t_1 : TC \; \overline{u}, t_2 : TC \; \overline{u}) &=& \{t_1 : TC \;
\overline{u}\}
\end{array}
\]
\caption{Given Binary Interaction Rules}
\label{fig:interact_g}
\end{figure}

\subsection{Simplification}
Simplification is highly similar to binary interaction but it transforms a
single wanted constraint using a given constraint, producing a new wanted
constraint. This rule does not consume the given constraint, only the wanted.

%TODO use numbers or labels?
At first glance it might seem that all of the binary interaction rules are here
as well. But the \textit{simplifies} rules are unidirectional and rules like
\[
\begin{array}{l}
simplifies(\gamma_1 : F(\overline{u}) \sim u_2, c_2 : a \sim u_1)
\\
simplifies(t : TC \; \overline{u}, c : a \sim u_1)
\end{array}
\]
are actually missing. These are not allowed because they introduce additional
type families and type class constraints that need to be solved. This is
dangerous for termination and does not contribute additional information that we
cannot derive from $a \sim u_1$.
%no evidence leaks to givens, strange comment, we don't simplify givens,

\begin{figure}
\small
\fbox{$simplifies(\mathcal{Q}_g, \mathcal{Q}) = \mathcal{Q}' \mid \eta$}
\[
\begin{array}{l c l}
simplifies(\gamma : a \sim u_1, c : a \sim u_2) &=& \{c' : u_1 \sim u_2\} \mid c
\mapsto \gamma \fctrans c'
\\ \where c' \; \text{fresh}
\\
simplifies(\gamma_1 : a \sim u_1, c : b \sim u_2)
\\ \guard a \in fv(u_2) &=& \{c' : b \sim \tau\} \mid c \mapsto c' \fctrans
\text{sym} \; \gamma_2
\\ \where [a \sim u_1](\gamma_1, u_2) \rightsquigarrow (\gamma_2, \tau)
\\ \whereindent c' \; \text{fresh}
\\
simplifies(\gamma_1 : a \sim u_1, c_2 : F(\overline{u}) \sim u_2)
\\ \guard a \in fv(\overline{u}) &=& \{c': \tau \sim u_2\} \mid c_2 \mapsto
\gamma_2 \fctrans c'
\\ \where [a \mapsto u_1](\gamma_1, F(\overline{u})) \rightsquigarrow (\gamma_2,
\tau)
\\ \whereindent c' \; \text{fresh}
\\
simplifies(\gamma_1 : a \sim u_1, d : TC \; \overline{u})
\\ \guard a \in fv(\overline{u}) &=& \{d' : \pi\} \mid d \mapsto
d' \triangleright \text{sym} \; \gamma_2
\\ \where [a \mapsto u_1](\gamma_1, TC \; \overline{u}) \rightsquigarrow
(\gamma_2, \pi)
\\ \whereindent d' \; \text{fresh}
\\
simplifies(\gamma_1 : F(\overline{u}) \sim u_1, c : F(\overline{u}) \sim u_2)
&=& \{c' : u_1 \sim u_2\} \mid c \mapsto \gamma_1 \fctrans c'
\\ \where c' \; \text{fresh}
\\
simplifies(t : TC \; \overline{u}, d : TC \; \overline{u}) &=& \bullet \mid d
\mapsto t
\end{array}
\]
\end{figure}

\subsection{Top-level Reactions}
The last set of rules we present are the top-level reaction rules, depicted
in figure~\ref{fig:topreact}. These rules are used to interact with top-level
class instance schemes and type equality axioms that get introduced by instance
declarations.

%TODO citation backward chaining?
For solving class constraints the standard \textit{backwards-chaining} method is
used. This method is specified in rule $topreactCls_w$. Instance declarations
are interpeted as logical implications, $\texttt{instance} \; \overline{\pi}
\Rightarrow \pi$ means that if all of the constraints in the premise
$\overline{\pi}$ are known or can be proven, we can prove $\pi$. Because we
start from the goal, we look for an declaration that proves it, assume that it
holds and attempt to prove the premises instead. Effectively working our way
backwards through the implications, hence the name \textit{backwards-chaining}.
For example:
\begin{verbatim}
    instance Eq Int
    instance Eq Bool
    instance (Eq a, Eq b) => Eq (a, b)
\end{verbatim}
To prove the wanted constraint \textit{Eq (Int, Bool)} the instance declaration
for \textit{Eq (a, b)} is used with $a$ instantiated with $Int$ and $b$ with
$Bool$. As a consequence the constraints in the premise are added as new wanted
constraints. Both of which can be solved in the next iterations where they will
match the instance declarations for \textit{Eq Int} and \textit{Eq Bool}
respectively. As these instances do not have premises, they will be completely
resolved without giving rise to new wanted constraints.
%TODO talk about evidence?

%TODO cite 2007a, mention solving in both directions
Equality axioms are are handled in a very similar way as binary interaction or
simplification. These are simply used as left-to-right substitutions. Unlike
wanted or given constraints, equality axioms and constraint schemes are
polymorphic. Simple Hindley-Milner unification, as depicted in
figure~\ref{fig:unify}, is used to produce a substitution that maps the
abstracted over type variables to the instantiated types. This why the free type
variables from the wanted or given constraints are included as untouchables. So
the substitution does not end up mapping type variables in the constraint to
those from the program theory because these may never end up in the resulting
System $F_C$ code. The axiom or constraint scheme does not match if
unification fails.

Note that top-level reaction for wanted equality and class constraints are
handled by two distinct rules. Reaction with class constraints must be delayed
until the very end.
%TODO why? only to prevent non-determinism with given class constraints? This
%used to be required to prevent matching issues before we added the free tyvs as
%untchs to unify. So equality related things had to happen first. No longer
%required so topreact as a whole can be deferred to last? should be cleaner

The top-level reaction rules are the only rules allowed to introduce additional
type families and type class constraints. To make sure that they do not harm
termination several restrictions are imposed on class and instance declarations.
More on these conditions is discussed in chapter~\ref{cha:conditions}.

\begin{figure}
\fbox{$topreactCls_w(\overline{a}_{utch}, P, \mathcal{Q}) = \mathcal{Q}' \mid \eta$}
\begin{mathpar}
\inferrule*[right=TopreactClsW]
{
    (d_I : \forall \overline{a} \overline{b}. \; \overline{\pi} \Rightarrow TC
    \; \overline{u}') \in P
    \\
    \overline{d}, \overline{b}' \; \text{fresh}
    \\
    \overline{a}_{utch}' = \overline{a}_{utch}, fv(\overline{u})
    \\
    \theta = [b \mapsto b'] \cdot unify(\overline{a}_{utch}', \overline{u \sim
    u'})
}
{
    topreactCls_w(\overline{a}_{utch}, P, d : TC \; \overline{u}) = \overline{d
    : \theta(\pi)} \mid d \mapsto d_I \; \theta(\overline{a} \overline{b}) \;
    \overline{d}
}
\end{mathpar}
\fbox{$topreactEq_w(\overline{a}_{utch}, P, \mathcal{Q}) = \mathcal{Q}' \mid \eta$}
\begin{mathpar}
\inferrule*[right=TopreactEqW]
{
    (g \; \overline{a} : F(\overline{u}') \sim \tau) \in P
    \\
    \overline{a}_{utch}' = \overline{a}_{utch}, fv(\overline{u},u)
    \\
    \theta = unify(\overline{a}_{utch}', \overline{u \sim u'})
}
{
    topreactEq_w(\overline{a}_{utch}, P, c : F(\overline{u}) \sim u) = c' :
    \theta(\tau) \sim u \mid c \mapsto g \; \theta(\overline{a}) \fctrans c'
}
\end{mathpar}
\fbox{$topreactEq_g(\overline{a}_{utch}, P,\mathcal{Q}_g) = \mathcal{Q}_g'$}
\begin{mathpar}
\inferrule*[right=TopreactGEq]
{
    (g \; \overline{a} : F(\overline{u}') \sim \tau) \in P
    \\
    \overline{a}_{utch}' = \overline{a}_{utch}, fv(\overline{u},u)
    \\
    \theta = unify(\overline{a}_{utch}', \overline{u \sim u'})
}
{
    topreactEq_g(\overline{a}_{utch}, P, \gamma : F(\overline{u}) \sim u) =
    \text{sym} \; (g \; \theta(\overline{a})) \fctrans \gamma : \theta(u') \sim
    u
}
\end{mathpar}
\caption{Top-level reaction rules}
\label{fig:topreact}
\end{figure}

\begin{figure}
%TODO appendix?
\fbox{$unify(\overline{a}; \overline{\phi}) = \theta_\bot$}
\[
\begin{array}{l c l}
unify(\overline{a}; \bullet) &=& \bullet
\\
unify(\overline{a}; \overline{\phi}, b \sim b) &=& unify(\overline{a};
\overline{\phi})
\\
unify(\overline{a}; \overline{\phi}, T \sim T) &=& unify(\overline{a};
\overline{\phi})
\\
unify(\overline{a}; \overline{\phi}, b \sim \tau)
\\ \guard b \notin \overline{a}, b \notin fv(\tau) &=& unify(\overline{a};
\theta(\overline{\phi})) \cdot \theta
\\ \where \theta = [b \mapsto \tau]
\\
unify(\overline{a}; \overline{\phi}, \tau \sim b)
\\ \guard b \notin \overline{a}, b \notin fv(\tau) &=& unify(\overline{a};
\theta(\overline{\phi})) \cdot \theta
\\ \where \theta = [b \mapsto \tau]
\\
unify(\overline{a}; \overline{\phi}, \tau_1 \; \tau_2 \sim \tau_3 \; \tau_4) &=&
unify(\overline{a}; \overline{\phi}, \tau_1 \sim \tau_3, \tau_2 \sim \tau_4)
\\
unify(\overline{a}; \overline{\phi}) &=& \bot
\end{array}
\]
\caption{Hindley-Milner Unification}
\label{fig:unify}
\end{figure}

\section{Solver structure}

%TODO define value for representing 'empty' or 'Nothing' when rule doesn't
%match?
%TODO really not sure in how much detail i should go, want to omit side-effects
%as well in this section
\subsection{Rule combinators}
In this section we define several abstractions for composing rules that are used
to implement the solver. The $liftR$ combinator lifts a rule from being applied
to single constraint to a set of constraints. A single constraint is
matched out of the set and the result is returned with the rest of the
constraints. The $\|$ operator represents non-deterministic choice, the first
rule is attempted and if it doesn't match the second one is used instead.

\begin{figure}
\begin{mathpar}
\inferrule*[right=Try]
{
  ~
}
{
  liftR(r, \overline{x}) = (x)
}
\\
\inferrule*[right=OrL]
{
  r_1
}
{
  r_1 \| r_2 = r_1
}
\quad
\inferrule*[right=OrR]
{
  r_2
}
{
  r_1 \| r_2 = r_2
}
\quad
\inferrule*[right=Fix]
{
  ~
}
{
  fix(r,x)
}
\end{mathpar}
\end{figure}

\subsection{Rule order}
Even though the algorithm was designed to be independent of the order in which
the rewrite rules fire, a decision has been made on a specific order. Because it
is strictly required for the soundness of the algorithm or so that the rules for
which we know that they don't apply to anything anymore are no longer attempted.
The latter is not required by any means but it did not make the solver more
complex.

Every rule except \textbf{canonicalization} expects canonical
constraints. Therefore this rule is exhaustively applied first. Afterwards,
other rules might produce additional rules that are not canonical and
canonicalization is applied just to the output of all other rules but not to the
entire set of constraints.

The set of \textbf{given} constraints is in no way affected by rewrite rules
involving wanted constraints and therefore we exhaustively apply all rules
exclusive to given constraints first.

%TODO rename topreact if name doesn't change
Lastly we do the same for all \textbf{wanted} constraints but these can't be
applied in any order. We must refrain from applying $topreact$ to class
constraints until the very end when no other rules apply. This is to prevent
issues related to non-determinism over given class constraints. For example:
\begin{verbatim}
    instance Eq a => Eq [a]
    f :: Eq [a] => [a] -> Bool
    f x = x == x
\end{verbatim}
The usage of \texttt{==} gives rise to the wanted constraint $Eq \; [a]$. This
could react with the instance declaration. This would result in the new wanted
constraint $Eq \; a$ for which we have no way of solving. However $Eq \; [a]$ could
easily be $simplified$ away using the given constraint $Eq \; [a]$ from the type
signature. Therefore, $topreact$ is applied last to prevent such situations.

\subsection{Building a substitution}

\begin{figure}
\fbox{$P ; \overline{a}_{utch} \vDash \mathcal{C} \rightsquigarrow
(\mathcal{P}_{residual}, \theta, \eta)_\bot$}
\begin{mathpar}
\inferrule*[right=Entail]
{
    solve(\overline{a}_{utch}, P, \mathcal{C}) \rightsquigarrow
    {\mathcal{C}_{residual} \mid \theta_{flat} ; \eta_{flat} ; \eta}_\bot
    \\
    \mathcal{C}_{flat} = \theta_{flat}(C_{residual})
    \\
    \mathcal{E}_{flat}, \mathcal{P}_{flat} \equiv \mathcal{C}_{flat}
    \\
    (\theta, \eta_{refl})_\bot = toSubst(\overline{a}_{utch}; \mathcal{E}_{flat})
}
{
    P ; \overline{a}_{utch} \vDash \mathcal{C} \rightsquigarrow
    (\theta(\mathcal{P}_{flat}), \theta, \eta_{refl} \cdot
    \eta_{flat}(\eta))_\bot
}
\end{mathpar}
\caption{Constraint Entailment}
\label{fig:entail}
\end{figure}
%TODO some sort of occurscheck here as well i think

After we get the normalized set of constraint with respect to the rewrite rules,
i.e. no rule applies to these constraints, all that is left to do is to apply
the flatting substitutions to the constraints and the evidence to undo the
flattening done by canonicalization. Afterwards, the resulting constraints are
split up in equality and type class constraints and these equality constraints
are used to build the type substitution. This final procedure of the entailment
relation is specified in figure~\ref{fig:entail}. The normalized and unflattened
equality constraints, denoted by $\mathcal{E}_{flat}$, should be very similar to
a substitution already. $\{ c_1 : a \sim \tau_1, c_2 : F \; \tau_2 \sim b,
\mathellipsis \}$, where $a$ and $b$ are not untouchable, simply needs to become
$[a \mapsto \tau_1, b \mapsto F \; \tau_2, \mathellipsis]$ and the evidence
simply becomes the reflection of the image of the type substitution $[ c_2
\mapsto \langle \tau_2 \rangle, c_2 \mapsto \langle \tau_2 \rangle,
\mathellipsis]$.

The $toSubst$ function specified in figure~\ref{fig:to-subst} constructs the
type substitution and additional evidence out of the constraints
$\mathcal{E}_{flat}$. The constraints $\mathcal{E}_{flat}$ and the resulting
substitution must have certain properties. Every constraint must have a shape
like $a \sim \tau$ or $\tau \sim a$ where $a \notin \overline{a}_{utch}$ and $a
\notin fv(\tau)$. $\mathcal{E}_{flat}$ should be void of inconsistencies like
$\{a \sim Int, a \sim Bool\}$ and the resulting substitution must be idempotent.
The procedure $toSubst$, inspired by unification, satisfies and verifies these
properties. Invalid constraints simply float upwards as residual equality
constraints and $toSubst$ presents an error to the user if it fails to solve all
constraints.

Note that this procedure could fail with a residual equality constraint like $F
\; Int \sim F \; Bool$, which doesn't always have to be inconsistent. In
practice, one could quantify over these constraints but because we disallow
equality constraints in the source syntax, we simply fail as with incosistent
constraints like $Bool \sim Int$.
\begin{figure}
\[
\begin{array}{l c l}
toSubst(\overline{a}_{utch}; \bullet) &=& (\bullet, \bullet)
\\
toSubst(\overline{a}_{utch}; \mathcal{E}, c : \tau \sim \tau) &=&
(\theta, \eta \cdot [c \mapsto \langle \tau \rangle] )
\\ \where (\theta, \eta) = toSubst(\overline{a}_{utch}, \mathcal{E})
\\
toSubst(\overline{a}_{utch}; \mathcal{E}, c : a \sim \tau)
\\ \guard a \notin \overline{a}_{utch} &=& (\theta \cdot [a \mapsto \tau], \eta
\cdot [c \mapsto \langle \tau \rangle])
\\ \where (\theta, \eta) = toSubst(\overline{a}_{utch}, [a \mapsto
\tau](\mathcal{E}))
\\
toSubst(\overline{a}_{utch}; \mathcal{E}, c : \tau \sim a)
\\ \guard a \notin \overline{a}_{utch} &=& (\theta \cdot [a \mapsto \tau], \eta
\cdot [c \mapsto \langle \tau \rangle])
\\ \where (\theta, \eta) = toSubst(\overline{a}_{utch}, [a \mapsto
\tau](\mathcal{E}))
\\
toSubst(\overline{a}_{utch}; \mathcal{E}) &=& \bot
\end{array}
\]
\caption{Build the substitution}
\label{fig:to-subst}
\end{figure}
